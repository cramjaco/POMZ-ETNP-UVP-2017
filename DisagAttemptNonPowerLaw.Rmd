---
title: "R Notebook"
output: html_notebook
---

The goal here is instead of assuming everything is a power law, I'll use a gam to interpolate each size bin.
Then we do the generally same analysis.

```{r}
library(tidyverse)
pass <- function(x){x}
```

Data from elsewhere
```{r, message= FALSE}
options(readr.default_locale=readr::locale(tz="Mexico/General"))
source("UVP_2017_library.R")

ES01 <- read_csv("dataOut/binned_EachSize.csv") %>% filter(depth <= 1000)
DS01 <- read_csv("dataOut/binned_DepthSummary.csv") %>% filter(depth <= 1000)
twinS <- list(ES01, DS01)
```

```{r}
SimpleBins <- seq(from = 0, to = 1100, by = 100)

#debug(bin_depths)
binnedS <- bin_depths(twinS, bins = SimpleBins) %>% calc_psd

ESS <- binnedS[[1]]
DSS <- binnedS[[2]]
```

Group by bin, and fit a gam to each bin.
Then predict the particle numbers back out.
We're going to work in `nparticle` space

```{r}
gaminate00 <- ESS %>% filter(profile == "stn_043") %>%
  select(depth, TotalParticles, vol, lb) %>%
  group_by(lb) %>% 
  nest(data = c(TotalParticles, vol, depth)) %>%
  pass

# I think I want to family gamma this if it goes negative; or maybe bust poisson back out
mygam <- function(df){gam(TotalParticles~depth, offset = vol, data = df, family = "poisson")} 

# gaminate01 <- gaminate00 %>% 
#   mutate(bingam = map(data, mygam)) %>%
#   mutate(pred = map2(bingam, data, predict)) %>%
#   mutate(predDf = map2(data, pred, tibble)) %>%
#   mutate(predDf = map(predDf, ~rename(., pred = 3))) %>%
#   select(lb, predDf) %>%
#   unnest(cols = c(predDf)) %>%
#   pass
  
# gaminate01 %>% head
```

```{r}
# gaminate01 %>% filter(lb == 0.102) %>% ggplot(aes(y = depth, x = nparticles)) + geom_point() + scale_y_reverse() +
#   geom_point(aes(x = pred), shape = 1)
```

```{r}
gaminate00[[2]][[1]] -> test
#glm(TotalParticles~log(depth), offset = vol, data = test[,], family = "poisson")
# below fails
# gam(TotalParticles~s(depth), offset = vol, data = test[-1,], family = poisson)
```

```{r}
ESS %>% filter(profile == "stn_043") %>% group_by(lb) %>% ggplot(aes(x = TotalParticles, y = depth, col = log(lb), group = lb)) + scale_y_reverse() + geom_point() + scale_x_log10() + scale_color_viridis_c() + geom_path() + geom_vline(xintercept = 5)
```

What if any time we see < 5 Total particles, we fill in from the power law. Otherwise we use the observed number?

Ok. Loess seems to work.

Order of operations
(1) if total particles < 5 (or similar), use psd_big and int_big to estimate nparticles in that bin
(2) interpolate every size bin down to small sizes
(3) recalculate things that need to be recalculated (like flux and what not)
(4) calculate disaggregation

```{r}
particle_data <- ESS %>% select(-nparticles, -n_nparticles, -time, -binsize)
```

# Without Pre-Binning
Forget pre-binning, that was mostly for stack overflow I think

Functionalize this
Uses psd to guess the number of particles when we see fewer than five of them
```{r}
get_np = function(icp, psd, bin, binsize){
  C_n = exp(icp)
  np = (C_n * bin ^ psd) * binsize
  np
}

ES02 <- ES01 %>%
  left_join(DS01 %>% select(profile, time, depth, big_psd, big_icp), by = c("profile", "time", "depth")) %>%
  mutate(nInterp = (exp(big_icp) * lb ^ big_psd) * binsize) %>%
  mutate(nparticles2 = if_else(TotalParticles < 5, nInterp, nparticles)) %>% 
  select(-big_icp, -big_psd)
```

Now, we want to make everything higher resolution.
I do this by using loess to get nparticles for every depth

```{r}

C_f = 10.51
ag = 0.78

ready_tibble <- tibble(depth = seq(from = 25, to = 1000, by = 25))

ES03 <- ES02 %>%
  filter(profile == "stn_043") %>%
  select(depth, lb, nparticles2) %>%
  group_by(lb) %>%
  #pull(depth) %>% unique %>%
  nest(data = c(depth, nparticles2)) %>%
  #mutate(loe = map(data, function(df) loess(nparticles2 ~ depth, data = df))) %>%
  mutate(loe = map(data, function(df) gam(nparticles2 ~ depth, data = df, family = "Gamma"))) %>%
  # the below column is awesome, but fails when set to map2_df, and is not actually the right solution
  #mutate(data2 = map2(loe, data, ~mutate(.y, pred = predict(.x, .y)))) %>%
  mutate(data2 = map(loe, ~mutate(ready_tibble, np = predict(., ready_tibble, type = "response")))) %>%
  select(-data, -loe) %>% unnest(cols = data2) %>%
  mutate(flux = np * C_f * lb ^ ag) %>%
  ungroup() %>%
  pass
  
ES03
```

Sanity check
```{r}

DS03 <- ES03 %>% group_by(depth) %>%
  nest(spec = c(lb, np, flux)) %>%
  ungroup() %>%
  mutate(Flux = map_dbl(spec, ~sum(.$flux))) %>%
  mutate(spec_only = map(spec, ~pull(., np)) )%>% 
  mutate(prev_spec = lag(spec_only)) %>%
  mutate(prev_Flux = lag(Flux)) %>%
  mutate(DF = prev_Flux - Flux, 
         DFP = Flux / prev_Flux) %>%
  pass

DS03
```

Now I think I want to make pred_spec here from prev_spec
I'll do this in three steps.

1) Use remin shuffle to get a new spec.
2) Now figure out what DFP needs to be to get the right flux
3) Recalculate spec with the corrected DFP

First a few tests
```{r}
test_abun_in <- DS03 %>% filter(depth == 25) %>% pull(spec) %>%.[[1]] %>% pull(np)
```

```{r}
test_abun_out <- remin_smooth_shuffle(test_abun_in, 0.9)
```

```{r}
tibble(lb = lb_vec, tin = test_abun_in, tout = test_abun_out) %>%
  pivot_longer(cols = c("tin", "tout")) %>%
  ggplot(aes(x = lb, y = value, color = name)) + geom_point() + scale_x_log10() + scale_y_log10() + cowplot::theme_cowplot()
```

```{r}
topt <- optFun(test_abun_in, 0.9)
topt
```

# Apply topt over everything

```{r}
DSA <- DS03 %>% slice(-1) %>%
  mutate(DFP_corrected = map2_dbl(prev_spec, DFP, optFun)) %>%
  mutate(prev_spec = map2(prev_spec, DFP_corrected, remin_smooth_shuffle))
DSA

```

I so don't remember what happens next.

# Graveyard
Degug
```{r}
DS03 %>% select(depth, Flux) %>% dput#%>% mutate(lFlux = lag(Flux))

```

```{r}
DS03[["spec"]][[1]][["np"]]
```


